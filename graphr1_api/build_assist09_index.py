"""
æ„å»º ASSIST09 çŸ¥è¯†è¶…å›¾çš„ FAISS ç´¢å¼•
ä» expanded_hypergraph.json ç”Ÿæˆï¼š
1. index_entity.bin - æ¦‚å¿µå®ä½“ç´¢å¼•
2. index_hyperedge.bin - å…ˆå†³å…³ç³»ï¼ˆè¶…è¾¹ï¼‰ç´¢å¼•
3. kv_store_entities.json - å®ä½“å…ƒæ•°æ®
4. kv_store_hyperedges.json - è¶…è¾¹å…ƒæ•°æ®
"""
import json
import numpy as np
import faiss
from FlagEmbedding import FlagAutoModel
from tqdm import tqdm
import os

print("="*80)
print("ASSIST09 çŸ¥è¯†è¶…å›¾ FAISS ç´¢å¼•æ„å»º")
print("="*80)

# ============================================================================
# 1. é…ç½®
# ============================================================================
HYPERGRAPH_PATH = "../data/assist09/kg_output_hypergraph/expanded_hypergraph.json"
OUTPUT_DIR = "expr/assist09_hypergraph"
EMBEDDING_MODEL = "BAAI/bge-large-en-v1.5"

os.makedirs(OUTPUT_DIR, exist_ok=True)

# ============================================================================
# 2. åŠ è½½åµŒå…¥æ¨¡å‹
# ============================================================================
print("\n[1/6] åŠ è½½åµŒå…¥æ¨¡å‹...")
model = FlagAutoModel.from_finetuned(
    EMBEDDING_MODEL,
    query_instruction_for_retrieval="Represent this sentence for searching relevant passages: ",
    devices="cpu",  # å¦‚æœæœ‰GPUï¼Œæ”¹ä¸º "cuda"
)
print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ: {EMBEDDING_MODEL}")

# ============================================================================
# 3. åŠ è½½çŸ¥è¯†è¶…å›¾
# ============================================================================
print("\n[2/6] åŠ è½½çŸ¥è¯†è¶…å›¾...")
with open(HYPERGRAPH_PATH, 'r', encoding='utf-8') as f:
    hypergraph = json.load(f)

concepts = hypergraph['concepts']
relations = hypergraph['prerequisite_relations']
stats = hypergraph['statistics']

print(f"âœ… è¶…å›¾åŠ è½½å®Œæˆ:")
print(f"  - æ¦‚å¿µæ•°: {stats['num_nodes']}")
print(f"  - å…³ç³»æ•°: {stats['num_edges']}")

# ============================================================================
# 4. æ„å»ºå®ä½“ï¼ˆæ¦‚å¿µï¼‰ç´¢å¼•
# ============================================================================
print("\n[3/6] æ„å»ºæ¦‚å¿µå®ä½“ç´¢å¼•...")

# 4.1 ä¸ºæ¯ä¸ªæ¦‚å¿µåˆ›å»ºæè¿°æ–‡æœ¬
entity_descriptions = []
kv_store_entities = {}

for idx, concept in enumerate(tqdm(concepts, desc="ç”Ÿæˆæ¦‚å¿µæè¿°")):
    # åˆ›å»ºä¸°å¯Œçš„æ¦‚å¿µæè¿°ï¼ˆç”¨äºæ›´å¥½çš„è¯­ä¹‰åŒ¹é…ï¼‰
    description = f"Knowledge Concept: {concept}. " \
                  f"This is a mathematical or educational concept related to learning and problem-solving."
    entity_descriptions.append(description)
    
    # ä¿å­˜åˆ° KV store
    kv_store_entities[str(idx)] = {
        'entity_id': str(idx),
        'entity_name': concept,
        'entity_type': 'concept',
        'description': description
    }

# 4.2 ç”ŸæˆåµŒå…¥
print("ç”Ÿæˆæ¦‚å¿µåµŒå…¥å‘é‡...")
entity_embeddings = model.encode(entity_descriptions)
entity_embeddings = np.array(entity_embeddings).astype('float32')

# 4.3 åˆ›å»º FAISS ç´¢å¼•
print("åˆ›å»º FAISS ç´¢å¼•...")
dimension = entity_embeddings.shape[1]
index_entity = faiss.IndexFlatIP(dimension)  # Inner Product (é€‚åˆå½’ä¸€åŒ–å‘é‡)
faiss.normalize_L2(entity_embeddings)  # L2 å½’ä¸€åŒ–
index_entity.add(entity_embeddings)

# 4.4 ä¿å­˜
entity_index_path = os.path.join(OUTPUT_DIR, 'index_entity.bin')
entity_kv_path = os.path.join(OUTPUT_DIR, 'kv_store_entities.json')

faiss.write_index(index_entity, entity_index_path)
with open(entity_kv_path, 'w', encoding='utf-8') as f:
    json.dump(kv_store_entities, f, indent=2, ensure_ascii=False)

print(f"âœ… å®ä½“ç´¢å¼•å·²ä¿å­˜:")
print(f"  - {entity_index_path}")
print(f"  - {entity_kv_path}")
print(f"  - å‘é‡ç»´åº¦: {dimension}")
print(f"  - ç´¢å¼•å¤§å°: {index_entity.ntotal}")

# ============================================================================
# 5. æ„å»ºè¶…è¾¹ï¼ˆå…ˆå†³å…³ç³»ï¼‰ç´¢å¼•
# ============================================================================
print("\n[4/6] æ„å»ºå…ˆå†³å…³ç³»ï¼ˆè¶…è¾¹ï¼‰ç´¢å¼•...")

# 5.1 ä¸ºæ¯æ¡å…³ç³»åˆ›å»ºæè¿°æ–‡æœ¬
hyperedge_descriptions = []
kv_store_hyperedges = {}

for idx, rel in enumerate(tqdm(relations, desc="ç”Ÿæˆå…³ç³»æè¿°")):
    source = rel['source']
    target = rel['target']
    rel_type = rel.get('type', 'prerequisite')
    confidence = rel.get('confidence', 'medium')
    
    # åˆ›å»ºå…³ç³»æè¿°
    if rel_type == 'atomic':
        description = f"Prerequisite Relation: '{source}' is a prerequisite for learning '{target}'. " \
                      f"Students should master {source} before studying {target}. " \
                      f"Confidence: {confidence}."
    else:  # hyperedge_expanded
        description = f"Learning Path: '{source}' leads to '{target}' through hyperedge expansion. " \
                      f"This represents a composite prerequisite relationship."
    
    hyperedge_descriptions.append(description)
    
    # ä¿å­˜åˆ° KV store
    kv_store_hyperedges[str(idx)] = {
        'hyperedge_id': str(idx),
        'source_entity': source,
        'target_entity': target,
        'relation_type': rel_type,
        'confidence': confidence,
        'content': description,
        'source_id': str(concepts.index(source)),
        'target_id': str(concepts.index(target))
    }

# 5.2 ç”ŸæˆåµŒå…¥
print("ç”Ÿæˆå…³ç³»åµŒå…¥å‘é‡...")
hyperedge_embeddings = model.encode(hyperedge_descriptions)
hyperedge_embeddings = np.array(hyperedge_embeddings).astype('float32')

# 5.3 åˆ›å»º FAISS ç´¢å¼•
print("åˆ›å»º FAISS ç´¢å¼•...")
index_hyperedge = faiss.IndexFlatIP(dimension)
faiss.normalize_L2(hyperedge_embeddings)
index_hyperedge.add(hyperedge_embeddings)

# 5.4 ä¿å­˜
hyperedge_index_path = os.path.join(OUTPUT_DIR, 'index_hyperedge.bin')
hyperedge_kv_path = os.path.join(OUTPUT_DIR, 'kv_store_hyperedges.json')

faiss.write_index(index_hyperedge, hyperedge_index_path)
with open(hyperedge_kv_path, 'w', encoding='utf-8') as f:
    json.dump(kv_store_hyperedges, f, indent=2, ensure_ascii=False)

print(f"âœ… è¶…è¾¹ç´¢å¼•å·²ä¿å­˜:")
print(f"  - {hyperedge_index_path}")
print(f"  - {hyperedge_kv_path}")
print(f"  - å‘é‡ç»´åº¦: {dimension}")
print(f"  - ç´¢å¼•å¤§å°: {index_hyperedge.ntotal}")

# ============================================================================
# 6. ä¿å­˜å›¾è°±å…ƒæ•°æ®
# ============================================================================
print("\n[5/6] ä¿å­˜å›¾è°±å…ƒæ•°æ®...")

metadata = {
    'dataset': 'assist09_hypergraph',
    'num_concepts': len(concepts),
    'num_relations': len(relations),
    'embedding_model': EMBEDDING_MODEL,
    'embedding_dimension': int(dimension),
    'index_entity_size': int(index_entity.ntotal),
    'index_hyperedge_size': int(index_hyperedge.ntotal),
    'relation_types': {
        'atomic': sum(1 for r in relations if r.get('type') == 'atomic'),
        'hyperedge_expanded': sum(1 for r in relations if r.get('type') == 'hyperedge_expanded')
    }
}

metadata_path = os.path.join(OUTPUT_DIR, 'metadata.json')
with open(metadata_path, 'w', encoding='utf-8') as f:
    json.dump(metadata, f, indent=2, ensure_ascii=False)

print(f"âœ… å…ƒæ•°æ®å·²ä¿å­˜: {metadata_path}")

# ============================================================================
# 7. æµ‹è¯•ç´¢å¼•
# ============================================================================
print("\n[6/6] æµ‹è¯•ç´¢å¼•...")

test_queries = [
    "What should I learn before studying quadratic equations?",
    "Prerequisites for algebra",
    "Basic concepts for geometry"
]

print("\næµ‹è¯•æŸ¥è¯¢ç»“æœ:")
for query in test_queries:
    print(f"\nğŸ” Query: {query}")
    
    # æŸ¥è¯¢åµŒå…¥
    query_embedding = model.encode_queries([query])
    query_embedding = np.array(query_embedding).astype('float32')
    faiss.normalize_L2(query_embedding)
    
    # æ£€ç´¢å®ä½“
    _, entity_ids = index_entity.search(query_embedding, 3)
    print(f"  Top 3 ç›¸å…³æ¦‚å¿µ:")
    for i, eid in enumerate(entity_ids[0], 1):
        print(f"    {i}. {concepts[eid]}")
    
    # æ£€ç´¢è¶…è¾¹
    _, hyperedge_ids = index_hyperedge.search(query_embedding, 3)
    print(f"  Top 3 ç›¸å…³å…³ç³»:")
    for i, hid in enumerate(hyperedge_ids[0], 1):
        rel = relations[hid]
        print(f"    {i}. {rel['source']} â†’ {rel['target']} ({rel.get('type', 'unknown')})")

# ============================================================================
# å®Œæˆ
# ============================================================================
print("\n" + "="*80)
print("âœ… ASSIST09 çŸ¥è¯†è¶…å›¾ç´¢å¼•æ„å»ºå®Œæˆï¼")
print("="*80)
print(f"\nç”Ÿæˆçš„æ–‡ä»¶:")
print(f"  ğŸ“ {OUTPUT_DIR}/")
print(f"    â”œâ”€â”€ index_entity.bin          ({os.path.getsize(entity_index_path) / 1024 / 1024:.2f} MB)")
print(f"    â”œâ”€â”€ index_hyperedge.bin       ({os.path.getsize(hyperedge_index_path) / 1024 / 1024:.2f} MB)")
print(f"    â”œâ”€â”€ kv_store_entities.json    ({os.path.getsize(entity_kv_path) / 1024:.2f} KB)")
print(f"    â”œâ”€â”€ kv_store_hyperedges.json  ({os.path.getsize(hyperedge_kv_path) / 1024:.2f} KB)")
print(f"    â””â”€â”€ metadata.json             ({os.path.getsize(metadata_path) / 1024:.2f} KB)")

print(f"\nä¸‹ä¸€æ­¥:")
print(f"  è¿è¡Œ API æœåŠ¡: python script_api_assist09.py")

