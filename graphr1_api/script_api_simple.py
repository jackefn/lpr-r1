"""
ASSIST09 çŸ¥è¯†è¶…å›¾ API æœåŠ¡ - ç®€åŒ–ç‰ˆ
ç›´æ¥ä½¿ç”¨ FAISS + çŸ¥è¯†å›¾è°±éå†ï¼Œä¸ä¾èµ– GraphR1
"""
import json
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import uvicorn
import faiss
from FlagEmbedding import FlagAutoModel
from typing import List, Dict, Optional
import argparse
import os
import networkx as nx

# ============================================================================
# é…ç½®
# ============================================================================
parser = argparse.ArgumentParser(description='ASSIST09 çŸ¥è¯†è¶…å›¾ API æœåŠ¡ - ç®€åŒ–ç‰ˆ')
parser.add_argument('--data_source', default='assist09_hypergraph', help='æ•°æ®æºåç§°')
parser.add_argument('--port', type=int, default=8002, help='API æœåŠ¡ç«¯å£')
parser.add_argument('--host', default='0.0.0.0', help='API æœåŠ¡åœ°å€')
args = parser.parse_args()

data_source = args.data_source
DATA_DIR = f"expr/{data_source}"
HYPERGRAPH_PATH = "../data/assist09/kg_output_hypergraph/expanded_hypergraph.json"

print("="*80)
print(f"ASSIST09 çŸ¥è¯†è¶…å›¾ API å¯åŠ¨ä¸­ï¼ˆç®€åŒ–ç‰ˆï¼‰...")
print("="*80)

# ============================================================================
# åŠ è½½åµŒå…¥æ¨¡å‹
# ============================================================================
print("\n[1/5] åŠ è½½åµŒå…¥æ¨¡å‹...")
model = FlagAutoModel.from_finetuned(
    'BAAI/bge-large-en-v1.5',
    query_instruction_for_retrieval="Represent this sentence for searching relevant passages: ",
    devices="cpu",
)
print("âœ… åµŒå…¥æ¨¡å‹åŠ è½½å®Œæˆ")

# ============================================================================
# åŠ è½½å®ä½“ç´¢å¼•
# ============================================================================
print("\n[2/5] åŠ è½½å®ä½“ï¼ˆæ¦‚å¿µï¼‰ç´¢å¼•...")
entity_index_path = os.path.join(DATA_DIR, 'index_entity.bin')
entity_kv_path = os.path.join(DATA_DIR, 'kv_store_entities.json')

index_entity = faiss.read_index(entity_index_path)
with open(entity_kv_path, 'r', encoding='utf-8') as f:
    entities = json.load(f)

corpus_entity = []
for item in entities:
    corpus_entity.append(entities[item]['entity_name'])

print(f"âœ… å®ä½“ç´¢å¼•åŠ è½½å®Œæˆ: {len(corpus_entity)} ä¸ªæ¦‚å¿µ")

# ============================================================================
# åŠ è½½è¶…è¾¹ç´¢å¼•
# ============================================================================
print("\n[3/5] åŠ è½½è¶…è¾¹ï¼ˆå…³ç³»ï¼‰ç´¢å¼•...")
hyperedge_index_path = os.path.join(DATA_DIR, 'index_hyperedge.bin')
hyperedge_kv_path = os.path.join(DATA_DIR, 'kv_store_hyperedges.json')

index_hyperedge = faiss.read_index(hyperedge_index_path)
with open(hyperedge_kv_path, 'r', encoding='utf-8') as f:
    hyperedges = json.load(f)

corpus_hyperedge = []
hyperedge_map = {}  # source -> target æ˜ å°„
for item in hyperedges:
    content = hyperedges[item]['content']
    corpus_hyperedge.append(content)
    source = hyperedges[item]['source_entity']
    target = hyperedges[item]['target_entity']
    if source not in hyperedge_map:
        hyperedge_map[source] = []
    hyperedge_map[source].append(target)

print(f"âœ… è¶…è¾¹ç´¢å¼•åŠ è½½å®Œæˆ: {len(corpus_hyperedge)} æ¡å…³ç³»")

# ============================================================================
# åŠ è½½çŸ¥è¯†å›¾è°±
# ============================================================================
print("\n[4/5] åŠ è½½çŸ¥è¯†å›¾è°±...")
with open(HYPERGRAPH_PATH, 'r', encoding='utf-8') as f:
    hypergraph_data = json.load(f)

# æ„å»º NetworkX å›¾
G = nx.DiGraph()
G.add_nodes_from(hypergraph_data['concepts'])
for rel in hypergraph_data['prerequisite_relations']:
    G.add_edge(rel['source'], rel['target'], **rel)

print(f"âœ… çŸ¥è¯†å›¾è°±åŠ è½½å®Œæˆ: {G.number_of_nodes()} èŠ‚ç‚¹, {G.number_of_edges()} è¾¹")

# ============================================================================
# æ ¸å¿ƒåŠŸèƒ½å‡½æ•°
# ============================================================================
def find_prerequisites(concept: str, max_depth: int = 3) -> List[Dict]:
    """æ‰¾åˆ°ä¸€ä¸ªæ¦‚å¿µçš„æ‰€æœ‰å‰ç½®æ¦‚å¿µ"""
    if concept not in G:
        return []
    
    prerequisites = []
    visited = set()
    
    def dfs(node, depth):
        if depth > max_depth or node in visited:
            return
        visited.add(node)
        
        for pred in G.predecessors(node):
            edge_data = G[pred][node]
            prerequisites.append({
                'prerequisite': pred,
                'target': node,
                'depth': depth,
                'type': edge_data.get('type', 'unknown'),
                'confidence': edge_data.get('confidence', 'medium')
            })
            dfs(pred, depth + 1)
    
    dfs(concept, 0)
    return prerequisites

def find_learning_path(start_concepts: List[str], target_concept: str) -> List[List[str]]:
    """æ‰¾åˆ°ä»èµ·ç‚¹æ¦‚å¿µåˆ°ç›®æ ‡æ¦‚å¿µçš„å­¦ä¹ è·¯å¾„"""
    paths = []
    for start in start_concepts:
        if start in G and target_concept in G:
            if nx.has_path(G, start, target_concept):
                try:
                    path = nx.shortest_path(G, start, target_concept)
                    paths.append(path)
                except:
                    pass
    return paths

def get_concept_info(concept: str) -> Dict:
    """è·å–æ¦‚å¿µçš„è¯¦ç»†ä¿¡æ¯"""
    if concept not in G:
        return None
    
    return {
        'name': concept,
        'in_degree': G.in_degree(concept),
        'out_degree': G.out_degree(concept),
        'prerequisites': list(G.predecessors(concept)),
        'dependents': list(G.successors(concept))
    }

# ============================================================================
# æŸ¥è¯¢å¤„ç†
# ============================================================================
async def process_queries(
    queries: List[str],
    top_k_retrieval: int = 5,
    max_depth: int = 3
) -> List[Dict]:
    """å¤„ç†æŸ¥è¯¢å¹¶è¿”å›ç»“æœ"""
    
    # 1. FAISS æ£€ç´¢
    embeddings = model.encode_queries(queries)
    _, entity_ids = index_entity.search(embeddings, top_k_retrieval)
    _, hyperedge_ids = index_hyperedge.search(embeddings, top_k_retrieval)
    
    results = []
    for i, query in enumerate(queries):
        # æ£€ç´¢åˆ°çš„å®ä½“
        entities_found = [corpus_entity[idx] for idx in entity_ids[i] if idx < len(corpus_entity)]
        
        # æ£€ç´¢åˆ°çš„å…³ç³»
        hyperedges_found = [corpus_hyperedge[idx] for idx in hyperedge_ids[i] if idx < len(corpus_hyperedge)]
        
        # å¯¹æ¯ä¸ªå®ä½“æ‰¾å‰ç½®æ¦‚å¿µ
        all_prerequisites = []
        learning_paths = []
        concept_details = []
        
        for entity in entities_found[:3]:  # åªå¤„ç† top 3
            # è·å–æ¦‚å¿µä¿¡æ¯
            info = get_concept_info(entity)
            if info:
                concept_details.append(info)
            
            # æ‰¾å‰ç½®æ¦‚å¿µ
            prereqs = find_prerequisites(entity, max_depth=max_depth)
            all_prerequisites.extend(prereqs)
            
            # æ‰¾å­¦ä¹ è·¯å¾„ï¼ˆä»æ ¹èŠ‚ç‚¹åˆ°è¯¥æ¦‚å¿µï¼‰
            root_nodes = [n for n in G.nodes() if G.in_degree(n) == 0]
            paths = find_learning_path(root_nodes[:5], entity)
            learning_paths.extend(paths)
        
        # æ„å»ºç»“æœ
        results.append({
            'query': query,
            'entity_candidates': entities_found,
            'hyperedge_candidates': hyperedges_found,
            'concept_details': concept_details,
            'prerequisites': all_prerequisites[:20],  # é™åˆ¶æ•°é‡
            'learning_paths': [{'path': p, 'length': len(p)-1} for p in learning_paths[:5]],
            'num_prerequisites': len(all_prerequisites),
            'num_paths': len(learning_paths)
        })
    
    return results

# ============================================================================
# FastAPI åº”ç”¨
# ============================================================================
app = FastAPI(
    title="ASSIST09 Knowledge Hypergraph API (Simplified)",
    description="ç®€åŒ–ç‰ˆ ASSIST09 çŸ¥è¯†è¶…å›¾æ£€ç´¢ API",
    version="1.0.0"
)

class SearchRequest(BaseModel):
    queries: List[str]
    top_k_retrieval: Optional[int] = 5
    max_depth: Optional[int] = 3

class SearchResponse(BaseModel):
    success: bool
    num_queries: int
    results: List[Dict]

@app.get("/")
async def root():
    return {
        "service": "ASSIST09 Knowledge Hypergraph API (Simplified)",
        "version": "1.0.0",
        "num_concepts": len(corpus_entity),
        "num_relations": len(corpus_hyperedge),
        "graph_nodes": G.number_of_nodes(),
        "graph_edges": G.number_of_edges()
    }

@app.get("/health")
async def health():
    return {"status": "healthy", "service": "running"}

@app.get("/concept/{concept_name}")
async def get_concept(concept_name: str):
    """è·å–å•ä¸ªæ¦‚å¿µçš„è¯¦ç»†ä¿¡æ¯"""
    info = get_concept_info(concept_name)
    if info is None:
        raise HTTPException(status_code=404, detail=f"æ¦‚å¿µ '{concept_name}' ä¸å­˜åœ¨")
    
    prereqs = find_prerequisites(concept_name, max_depth=5)
    return {
        **info,
        'all_prerequisites': prereqs
    }

@app.post("/search", response_model=SearchResponse)
async def search(request: SearchRequest):
    """æœç´¢æ¥å£"""
    try:
        if not request.queries:
            raise HTTPException(status_code=400, detail="æŸ¥è¯¢åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
        
        results = await process_queries(
            request.queries,
            top_k_retrieval=request.top_k_retrieval,
            max_depth=request.max_depth
        )
        
        return SearchResponse(
            success=True,
            num_queries=len(request.queries),
            results=results
        )
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å¤„ç†æŸ¥è¯¢æ—¶å‡ºé”™: {str(e)}")

# ============================================================================
# å¯åŠ¨æœåŠ¡
# ============================================================================
if __name__ == "__main__":
    print("\n" + "="*80)
    print("ğŸš€ å¯åŠ¨ API æœåŠ¡ï¼ˆç®€åŒ–ç‰ˆï¼‰...")
    print("="*80)
    print(f"åœ°å€: http://{args.host}:{args.port}")
    print(f"æ–‡æ¡£: http://{args.host}:{args.port}/docs")
    print("="*80 + "\n")
    
    uvicorn.run(app, host=args.host, port=args.port)

